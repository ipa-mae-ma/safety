################################
# A3C from 'Asynchronous Methods for Deep Reinforcement Learning' by Mnih et al. 2016
################################
gamma: 0.99
replay_memory_size: 10000
################################
# Asynchronous
################################
threads: 8
thread_delay: 0.001
n_step_return: 8
loss_value_coefficient: 0.5
loss_entropy_coefficient: 0.01

################################
# RMSprop
################################
kernel_initializer: he_uniform
learning_rate: 0.005

################################
# epsilon greedy
################################
epsilon: 1.0
epsilon_min: 0.1
eps_max_frame: 100000

################################
# training
################################
num_epochs: 5
num_episodes: 100
num_steps: 300
neurons: 250
random_seed: 1234
action_dim: 4


mini:
  ################################
  gamma: 0.99
  replay_memory_size: 10000
  ################################
  threads: 1
  n_step_return: 8
  loss_value_coefficient: 0.5
  loss_entropy_coefficient: 0.01
  ################################
  kernel_initializer: he_uniform
  learning_rate: 0.001
  ################################
  epsilon: 0.1
  epsilon_min: 0.01
  eps_max_frame: 100000
  ################################
  num_epochs: 10
  num_episodes: 100
  num_steps: 1500
  neurons: 250
  random_seed: 1234

small:
  ################################
  gamma: 0.85
  replay_memory_size: 10000
  ################################
  threads: 8
  n_step_return: 8
  loss_value_coefficient: 0.5
  loss_entropy_coefficient: 0.01
  ################################
  kernel_initializer: he_uniform
  learning_rate: 0.005
  ################################
  epsilon: 1.0
  epsilon_min: 0.1
  eps_max_frame: 100000
  ################################
  num_epochs: 5
  num_episodes: 100
  num_steps: 300
  neurons: 250
  random_seed: 1234
