################################
# DQN from 'Human-level control through deep reinforcement learning' by Mnih et al. 2015
################################
minibatch_size: 32
replay_memory_size: 10000
gamma: 0.99

################################
# RMSprop
################################
optimizer: RMSProp
kernel_initializer: he_uniform
learning_rate: 0.0005
gradient_momentum: 0.95
squared_gradient_momentum: 0.95
min_squared_gradient: 0.01

################################
# epsilon greedy
################################
annealing: True
epsilon: 1.0
epsilon_min: 0.1
eps_max_frame: 100000


################################
# training
################################
num_epochs: 5
num_episodes: 100
num_steps: 300
target_network_update_frequency: 500
neurons: 250

random_seed: 1234
action_dim: 4


mini:
  ################################
  minibatch_size: 32
  # replay buffer size
  # DQN size 1.0e6
  # HRA size: 10000
  replay_memory_size: 10000
  # gamma from HRA: 0.85
  gamma: 0.85
  ################################
  optimizer: RMSProp
  kernel_initializer: he_uniform
  learning_rate: 0.000025
  # lr from HRA: 0.0005
  gradient_momentum: 0.95
  squared_gradient_momentum: 0.95
  min_squared_gradient: 0.01
  ################################
  annealing: True
  epsilon: 1.0
  epsilon_min: 0.1
  eps_max_frame: 100000
  ################################
  num_epochs: 50
  num_episodes: 100
  num_steps: 300
  target_network_update_frequency: 500
  neurons: 250
  random_seed: 1234

small:
  ################################
  minibatch_size: 32
  # replay buffer size
  # DQN size 1.0e6
  # HRA size: 10000
  replay_memory_size: 50000
  # gamma from HRA: 0.85
  gamma: 0.85
  ################################
  optimizer: RMSProp
  kernel_initializer: he_uniform
  # lr from HRA: 0.0005
  learning_rate: 0.000025
  gradient_momentum: 0.95
  squared_gradient_momentum: 0.95
  min_squared_gradient: 0.01
  ################################
  annealing: True
  epsilon: 1.0
  epsilon_min: 0.1
  eps_max_frame: 150000
  ################################
  num_epochs: 20
  num_episodes: 100
  num_steps: 1000
  target_network_update_frequency: 1200
  neurons: 250
  random_seed: 1234


aperture:
  ################################
  minibatch_size: 32
  # replay buffer size
  # DQN size 1.0e6
  # HRA size: 10000
  replay_memory_size: 100000
  # gamma from HRA: 0.85
  gamma: 0.85
  ################################
  kernel_initializer: he_uniform
  learning_rate: 0.00025
  # lr from HRA: 0.0005
  gradient_momentum: 0.95
  squared_gradient_momentum: 0.95
  min_squared_gradient: 0.01
  ################################
  annealing: True
  epsilon: 1.0
  epsilon_min: 0.1
  eps_max_frame: 1000000
  ################################
  num_epochs: 500
  num_episodes: 100
  num_steps: 1500
  target_network_update_frequency: 2000
  neurons: 250
  random_seed: 1234