################################
# DQN from 'Human-level control through deep reinforcement learning' by Mnih et al. 2015
################################
minibatch_size: 32
# DQN size
# replay_memory_size: 1.0e6
# HRA size
replay_memory_size: 10000
# gamma: 0.99
gamma: 0.85

################################
# RMSprop
################################
# learning_rate: 0.00025
learning_rate: 0.000025
# learning_rate: 0.00000025
# lr from HRA
# learning_rate: 0.001
gradient_momentum: 0.95
squared_gradient_momentum: 0.95
min_squared_gradient: 0.01

################################
# epsilon greedy
################################
annealing: True
epsilon: 1.0
epsilon_min: 0.1
eps_max_frame: 100000
test_epsilon: 0.0


################################
# training
################################
num_epochs: 50
num_episodes: 100
num_steps: 300
# target_network_update_frequency: 10000
target_network_update_frequency: 500

rendering: False
nb_experiments: 1
random_seed: 1234
total_eps: 5000
is_learning: True
eps_per_epoch: 10
max_start_nullops: 0
is_testing: True
eps_per_test: 100
episode_max_len: 300
folder_location: '/results/'
test: False


history_len: 1
replay_max_size: 10000
replay_min_size: 1000
learning_frequency: 4
action_dim: 4
num_units: 250
